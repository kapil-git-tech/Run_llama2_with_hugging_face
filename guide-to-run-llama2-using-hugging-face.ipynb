{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/kapilstp84/guide-to-run-llama2-using-hugging-face?scriptVersionId=139981918\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# Beginner's Guide to run llama2 using hugging face\n\n### Running llama 2 on kaggle after getting the access from meta\n\n### Below notebook also provides a comparison of output from Llama2 7b & ChatGPT\n\n* Make sure you have necessary permissions to access the hugging face repository name. If not, follow the below steps:\n* Go to meta website & login/sign-up. Use the same email id/username to get permissions to use Llama2 via hugging face. It takes 1-2 days for permissions to be granted by meta team (generally takes few hours)\n\n### In this example we run pre-trained model \"meta-llama/Llama-2-7b-chat-hf\"","metadata":{}},{"cell_type":"markdown","source":"## Creating token to login to Hugging Face\n\n* To access private repositories or specific resources on the Hugging Face model hub, you'll need an authentication token. \n* This token verifies your identity and permissions. You can generate a token from your Hugging Face account settings. \n* Visit https://huggingface.co/settings/tokens while logged in to your Hugging Face account.\n* Click on \"New Token\" to generate a new token.Provide a name for the token (e.g., \"My Token for Hugging Face CLI\"). Click \"Create\" to generate the token.","metadata":{}},{"cell_type":"code","source":"pip install transformers","metadata":{"execution":{"iopub.status.busy":"2023-08-15T11:02:46.883546Z","iopub.execute_input":"2023-08-15T11:02:46.883946Z","iopub.status.idle":"2023-08-15T11:02:57.548235Z","shell.execute_reply.started":"2023-08-15T11:02:46.883916Z","shell.execute_reply":"2023-08-15T11:02:57.546553Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.30.2)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.65.0)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.5.7)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from huggingface_hub import login\nlogin()\n\n#Pass the hugging face token below, when prompted","metadata":{"execution":{"iopub.status.busy":"2023-08-15T11:03:01.025646Z","iopub.execute_input":"2023-08-15T11:03:01.026041Z","iopub.status.idle":"2023-08-15T11:03:01.210774Z","shell.execute_reply.started":"2023-08-15T11:03:01.026009Z","shell.execute_reply":"2023-08-15T11:03:01.2096Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"88efe83ed3a843f1bf66ffec5f661498"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModelForSequenceClassification, AutoModelForCausalLM, TrainingArguments, Trainer\n\nmodel_name = \"meta-llama/Llama-2-7b-chat-hf\"\nTokenizer = AutoTokenizer.from_pretrained(model_name)","metadata":{"execution":{"iopub.status.busy":"2023-08-15T11:03:14.778197Z","iopub.execute_input":"2023-08-15T11:03:14.778969Z","iopub.status.idle":"2023-08-15T11:03:32.581365Z","shell.execute_reply.started":"2023-08-15T11:03:14.778939Z","shell.execute_reply":"2023-08-15T11:03:32.579819Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:98: UserWarning: unable to load libtensorflow_io_plugins.so: unable to open file: libtensorflow_io_plugins.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io_plugins.so: undefined symbol: _ZN3tsl6StatusC1EN10tensorflow5error4CodeESt17basic_string_viewIcSt11char_traitsIcEENS_14SourceLocationE']\n  warnings.warn(f\"unable to load libtensorflow_io_plugins.so: {e}\")\n/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/__init__.py:104: UserWarning: file system plugins are not loaded: unable to open file: libtensorflow_io.so, from paths: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so']\ncaused by: ['/opt/conda/lib/python3.10/site-packages/tensorflow_io/python/ops/libtensorflow_io.so: undefined symbol: _ZTVN10tensorflow13GcsFileSystemE']\n  warnings.warn(f\"file system plugins are not loaded: {e}\")\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/776 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f98b88b07a244cab308f690296db67e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading tokenizer.model:   0%|          | 0.00/500k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0704e9ed5af84de8bd0e5c51402bb817"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.84M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eed7119e341c450687563c9b174744a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/414 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e23b9ee3850c4e0981cfa2c2a49fbfff"}},"metadata":{}}]},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(model_name, use_auth_token=\"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\")","metadata":{"execution":{"iopub.status.busy":"2023-08-15T11:03:32.583381Z","iopub.execute_input":"2023-08-15T11:03:32.58407Z","iopub.status.idle":"2023-08-15T11:06:47.325916Z","shell.execute_reply.started":"2023-08-15T11:03:32.584039Z","shell.execute_reply":"2023-08-15T11:06:47.324954Z"},"trusted":true},"execution_count":4,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/614 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d826ec203f0491b9d7fa099985740a4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)fetensors.index.json:   0%|          | 0.00/26.8k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a232a631c3e940f885a467da4696fb6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8e0662fa3ec84ed3bb70b4a95ac5645b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00002.safetensors:   0%|          | 0.00/9.98G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"39a2000160fc4b87a4897964eeb49b29"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)of-00002.safetensors:   0%|          | 0.00/3.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d55fd1dd42004c4b83a081c1a2cac059"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3571d8be2d5d4da5bde76dbbdd96945d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)neration_config.json:   0%|          | 0.00/188 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"779502ae3b3b491dba302996ccc6701e"}},"metadata":{}}]},{"cell_type":"markdown","source":"### This below \"input\" part of the code is related to tokenizing text using the Hugging Face Transformers library, likely using a pre-trained tokenizer for natural language processing tasks.\n\n* Input_text is a variable that holds a text string. What ever you want to input into the model.\n* Tokenizer refers to a tokenizer object from the Hugging Face Transformers library. A tokenizer is used to process text data and convert it into a format that machine learning models can understand. It typically divides the text into tokens, converts them into numerical values (IDs)\n* The encode method of the tokenizer is being used to process the Input_text. It takes the input text and converts it into a format that can be fed into a machine learning model.\n* The return_tensors parameter specifies the format in which the encoded data should be returned. In this case, 'pt' stands for PyTorch tensors.\n\n### In Summary, the code takes the Input_text, encodes it using a tokenizer, and returns the encoded text as PyTorch tensors. This encoded text can then be used as input for various natural language processing tasks, such as language generation, sentiment analysis, or text classification, using pre-trained models available in the Hugging Face Transformers library.","metadata":{}},{"cell_type":"code","source":"Input_text = \"My favourite movie is The Departed. Can you recommend me other similar movies i might like?\"\nInputs = Tokenizer.encode(Input_text, return_tensors = 'pt')","metadata":{"execution":{"iopub.status.busy":"2023-08-15T11:06:47.329275Z","iopub.execute_input":"2023-08-15T11:06:47.330223Z","iopub.status.idle":"2023-08-15T11:06:47.370808Z","shell.execute_reply.started":"2023-08-15T11:06:47.330182Z","shell.execute_reply":"2023-08-15T11:06:47.369734Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"### This below \"output\" part of the code is related to using a language generation model from the Hugging Face Transformers library to generate text based on a given input.\n\n> * Outputs is a variable that will hold the generated text sequences. It will store the text sequences that are generated by the model.\n> * model refers to a language generation model from the Hugging Face Transformers library.\n> * The generate method of the model is being used to generate text. This method takes various parameters to control the generation process.\n> * Inputs likely holds the encoded input text that you've previously prepared using a tokenizer. This input text serves as a seed or prompt for the language generation model.\n> * The max_length parameter specifies the maximum length of the generated text sequences.\n> * The num_return_sequences parameter specifies how many different text sequences you want the model to generate. \n> * The temperature parameter controls the randomness of the generation process. A higher value (e.g., 1.0) makes the generated text more random, while a lower value (e.g., 0.7) makes it more focused and deterministic.","metadata":{}},{"cell_type":"code","source":"# Generate text\noutputs = model.generate(Inputs, max_length=100, num_return_sequences=5, temperature=0.7)\n\n# Print generated text\nprint(\"Generated text:\")\nfor i, output in enumerate(outputs):\n    # Decode the generated output text\n    decoded_output = Tokenizer.decode(output)\n    \n    # Find the index where the decoded output text starts\n    start_index = decoded_output.find(Input_text) + len(Input_text)\n    \n    # Extract and print the generated text without the input/question\n    generated_text = decoded_output[start_index:]\n    print(f\"{i}: {generated_text}\")","metadata":{"execution":{"iopub.status.busy":"2023-08-15T11:06:47.372767Z","iopub.execute_input":"2023-08-15T11:06:47.373094Z","iopub.status.idle":"2023-08-15T11:12:53.484654Z","shell.execute_reply.started":"2023-08-15T11:06:47.373065Z","shell.execute_reply":"2023-08-15T11:12:53.483299Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Generated text:\n0: \n\nI'm looking for a crime drama with complex characters, gripping storylines, and great performances.\n\nThanks!</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n1: \n\nI am a big fan of crime dramas, especially those that explore themes of loyalty, betrayal, and redemption. I also enjoy movies with complex characters and intricate plots.\n\nSome other movies I have enjoyed in the past include:\n\n* Goodfellas\n* Scarface\n* The Godfather\n* American\n2: \n\nThe Departed is a crime drama directed by Martin Scorsese, starring Leonardo DiCaprio, Matt Damon, Jack Nicholson and Vera Farmiga. It tells the story of an undercover cop who infiltrates a Boston crime syndicate, while a mole within the police department works to uncover his identity. The movie explores themes\n3: \n\nI'm a big fan of crime dramas and I think The Departed has a great cast and an intriguing storyline. If you have any recommendations for similar movies, please let me know!</s><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk><unk>\n4: \nI think you will enjoy these movies:\n\n1. Goodfellas (1990) - A crime drama that follows the rise and fall of a mobster, similar to The Departed in its exploration of the criminal underworld.\n2. Scarface (1983) - A classic crime drama that explores the rise of a\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# CHATGPT Response to the same prompt:\n\n### My favourite movie is The Departed. Can you recommend me other similar movies i might like?\n### Return only 5 sequences with max length = 500\n\n### For the above prompt on **ChatGPT**, i got the follwing response:\n\nCertainly! If you loved \"The Departed,\" you might also enjoy these:\n\nInfernal Affairs (2002) - Hong Kong thriller, undercover cops.\n\nHeat (1995) - Crime, detective vs. criminal.\n\nDonnie Brasco (1997) - FBI agent infiltrates mafia.\n\nThe Town (2010) - Bank robbers, moral conflicts.\n\nAmerican Gangster (2007) - Detective vs. drug lord.","metadata":{}}]}